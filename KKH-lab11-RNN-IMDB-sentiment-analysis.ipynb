{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"KKH-lab11-RNN-IMDB-sentiment-analysis.ipynb","provenance":[{"file_id":"1GAo8fY2jbv5XFZ57CZ9jEjL0m5A-n05N","timestamp":1636432609347},{"file_id":"1Ofc3BdE9xJEnzTFE9fx3_QTed8Hh2RVt","timestamp":1636192353673},{"file_id":"https://github.com/scoutbee/pytorch-nlp-notebooks/blob/develop/3_rnn_text_classification.ipynb","timestamp":1635329409655}],"collapsed_sections":["hOS97iA-YqZR"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9800898548154e8f9f89ed5c5655bae7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ca36eefa91e44d73b6db520a64ae3876","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_36de6a8031a64d87b7c214fdd523fa64","IPY_MODEL_b3aa84681ee14afaa951189a321e916a","IPY_MODEL_4220c3771ee946ca93cacfa068384958"]}},"ca36eefa91e44d73b6db520a64ae3876":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36de6a8031a64d87b7c214fdd523fa64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8d72e02b8a844919b58d0f6c2a54bd51","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 1 Loss: 0.6877: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f04eb559cb0145a3a88a6692dadbb5bc"}},"b3aa84681ee14afaa951189a321e916a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0bdffd4e7fee43129a59c21603b6a73d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":31,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":31,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e178607365ca41cd89961a88f43e6f90"}},"4220c3771ee946ca93cacfa068384958":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5b353ec9114a44e5b3cbcfa8b1ec5eb7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 31/31 [00:52&lt;00:00,  1.40s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e8a728c9f1294be89560685294009c19"}},"8d72e02b8a844919b58d0f6c2a54bd51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f04eb559cb0145a3a88a6692dadbb5bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0bdffd4e7fee43129a59c21603b6a73d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e178607365ca41cd89961a88f43e6f90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b353ec9114a44e5b3cbcfa8b1ec5eb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e8a728c9f1294be89560685294009c19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55957763cfee48e880999df6f704c737":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_19b6d406277e4e4681c127ca2dcc6bca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1e18a34fe3014ff09189a55c10cc0d0b","IPY_MODEL_e3d050c07d53432299b306bd55efcb0e","IPY_MODEL_7570ff4372bd4ea9a0d29108e4fb4ce2"]}},"19b6d406277e4e4681c127ca2dcc6bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e18a34fe3014ff09189a55c10cc0d0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c11ebc23abe747d4aba838e94bd88cb2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 2 Loss: 0.6773: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_636542f0f94045bea2d58aa8f4abb31b"}},"e3d050c07d53432299b306bd55efcb0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a6b0b3e9580e42e5bedc2eacc6561405","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":31,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":31,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a13b9dfd8c6404ebe0d1d1a3af79f3f"}},"7570ff4372bd4ea9a0d29108e4fb4ce2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_30bf739a33b348e182a8aeac6b8b0844","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 31/31 [00:52&lt;00:00,  1.40s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ca7759262674824a5a8a35fb8cabab8"}},"c11ebc23abe747d4aba838e94bd88cb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"636542f0f94045bea2d58aa8f4abb31b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a6b0b3e9580e42e5bedc2eacc6561405":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5a13b9dfd8c6404ebe0d1d1a3af79f3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30bf739a33b348e182a8aeac6b8b0844":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ca7759262674824a5a8a35fb8cabab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54c6ad8c096a467a998384d004d82248":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_600d670a56e847fb91cfd745ed0349ce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_28231e2667034f389ac51281dfd6d146","IPY_MODEL_b18ed2bc32c245158253dcbb9a75fbd0","IPY_MODEL_b504dbbcf6d64425a4935ba4e9bd0cd1"]}},"600d670a56e847fb91cfd745ed0349ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28231e2667034f389ac51281dfd6d146":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c9b9485fb96348d39dbef54eec004000","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 3 Loss: 0.6663: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_813c0c74d4e042fdbe7a7b6bb216df96"}},"b18ed2bc32c245158253dcbb9a75fbd0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2fdb294e1c4d42a797ed6c23bab36109","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":31,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":31,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1babf6c62a1542da8cb1d53b731c4882"}},"b504dbbcf6d64425a4935ba4e9bd0cd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eaff0af0703149c294e0d29673eac072","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 31/31 [00:52&lt;00:00,  1.39s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fae169a289224a999c6c1812d414297c"}},"c9b9485fb96348d39dbef54eec004000":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"813c0c74d4e042fdbe7a7b6bb216df96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2fdb294e1c4d42a797ed6c23bab36109":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1babf6c62a1542da8cb1d53b731c4882":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eaff0af0703149c294e0d29673eac072":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fae169a289224a999c6c1812d414297c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3a69e764a3f41d188fab7dabdf38894":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ef5e176d3d9743e081552827d8353722","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_544cb1d3971c46f79beecddc02470e37","IPY_MODEL_d0f398fa0be24debb7d40bd77c3558d0","IPY_MODEL_0ed2c1f79f474ba8ac85966ce62a2388"]}},"ef5e176d3d9743e081552827d8353722":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"544cb1d3971c46f79beecddc02470e37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_921495eae30a4726b781bac0dae2b959","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 1 Loss: 0.6949: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b563fb7ec874809b9b2e321ac3cf6a8"}},"d0f398fa0be24debb7d40bd77c3558d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fc7c03c6744d4b869c5301f168ebc8e0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":31,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":31,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6b736234db247e7b05bb57088cb76d2"}},"0ed2c1f79f474ba8ac85966ce62a2388":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d92a171c7f7e4d1296531ed648c157bd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 31/31 [03:03&lt;00:00,  5.14s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee6a57a1d444487e97c4c58f097aa098"}},"921495eae30a4726b781bac0dae2b959":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3b563fb7ec874809b9b2e321ac3cf6a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc7c03c6744d4b869c5301f168ebc8e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c6b736234db247e7b05bb57088cb76d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d92a171c7f7e4d1296531ed648c157bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ee6a57a1d444487e97c4c58f097aa098":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"915e0717f6ea43eda546f684fecebc38":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1be00d580070428d9e967b15f079b078","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9711566fff0b408abd42fb3de1facf3a","IPY_MODEL_553dde379612407f93c75593b572ac53","IPY_MODEL_628d086cff704f09b5eafb79e960ae22"]}},"1be00d580070428d9e967b15f079b078":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9711566fff0b408abd42fb3de1facf3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8af88be225b84fb9b0e08233dc182b36","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 2 Loss: 0.6936: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9a6b0508d15649c292b6ed8614081a37"}},"553dde379612407f93c75593b572ac53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_58d5325d5d6c43edad7197874d87b175","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":31,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":31,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37cb57eb8fc244e99e42b4facce4c8b5"}},"628d086cff704f09b5eafb79e960ae22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_173a1b7236f84e1a92dad447db7cbd10","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 31/31 [03:02&lt;00:00,  5.17s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b02287ce8714e02b9507284475933d0"}},"8af88be225b84fb9b0e08233dc182b36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9a6b0508d15649c292b6ed8614081a37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58d5325d5d6c43edad7197874d87b175":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"37cb57eb8fc244e99e42b4facce4c8b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"173a1b7236f84e1a92dad447db7cbd10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8b02287ce8714e02b9507284475933d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c7ba090d9f8842199b133180238a8610":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ba8968d0265541809daa9eb2b597731c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_98862015c7244e91a3521778059d2f90","IPY_MODEL_de83f125bb5049baa9b897fc3dff2bf0","IPY_MODEL_7a9dd3b606474b99a772da2235b8a316"]}},"ba8968d0265541809daa9eb2b597731c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98862015c7244e91a3521778059d2f90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea5d56cc5b82480da9a46c9611d33a87","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 3 Loss: 0.6928: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20cce72dd1f44ebdb4cda0f28e6c8371"}},"de83f125bb5049baa9b897fc3dff2bf0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0be1db1aa9f3440e98f33b89a064a10c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":31,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":31,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30f0400023844543a83f8cfa9c08ec86"}},"7a9dd3b606474b99a772da2235b8a316":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d3cdcc1995b64496b4cadbbeaa5d32f7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 31/31 [03:02&lt;00:00,  5.14s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bf4b6b06a79f4bd79570586b78dee010"}},"ea5d56cc5b82480da9a46c9611d33a87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20cce72dd1f44ebdb4cda0f28e6c8371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0be1db1aa9f3440e98f33b89a064a10c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30f0400023844543a83f8cfa9c08ec86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3cdcc1995b64496b4cadbbeaa5d32f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bf4b6b06a79f4bd79570586b78dee010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"hOS97iA-YqZR"},"source":["# Lab 11: Using `CountVectorizer()` & RNN Text Classification\n","- We wiill walk through an example to understand how sklearn's `CountVectorizer()` works\n","- And then we will use `CountVectorizer` and RNNs to perform Sentiment Analysis on IMDB reviews"]},{"cell_type":"code","metadata":{"id":"GavNnGaE_sD_"},"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Btt9Sj09Owju"},"source":["### CountVectorizer()\n","- Converts a collection of text documents to a matrix of token counts in each document"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h24iLBMELpCZ","executionInfo":{"status":"ok","timestamp":1637160475757,"user_tz":-540,"elapsed":372,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"05c85c25-3de4-4162-8f7b-527c6c9ef8d0"},"source":["corpus = ['Hello there world!',\n","'There is a cat',\n","'I\\'m a dreamer...',\n","'There there dreamer cat',\n","'And the answer is...42']\n","\n","count_vect = CountVectorizer()\n","count_matrix = count_vect.fit_transform(corpus)\n","# Convert matrix to array\n","count_array = count_matrix.toarray()\n","# Convert array to data frame, dtm (document term matrix)\n","dtm = pd.DataFrame(data=count_array, \n","                   columns=count_vect.get_feature_names())\n","print(dtm)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   42  and  answer  cat  dreamer  hello  is  the  there  world\n","0   0    0       0    0        0      1   0    0      1      1\n","1   0    0       0    1        0      0   1    0      1      0\n","2   0    0       0    0        1      0   0    0      0      0\n","3   0    0       0    1        1      0   0    0      2      0\n","4   1    1       1    0        0      0   1    1      0      0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"jlhKlp1tO3R7"},"source":["# Q1. How many tokens were created by CountVectorizer()?\n","# 10 tokens\n","\n","# Q2. Apart from splitting by white space, what other pre-processing was done by CountVectorizer?\n","# The removal of dot(.) and \\ was done by it"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VHUhrDlpc58U"},"source":["View the tokens and vocabulary"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HveNZmphc7-4","executionInfo":{"status":"ok","timestamp":1637160481526,"user_tz":-540,"elapsed":362,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"a0eb54b2-b366-472a-ea89-5e585c874036"},"source":["print(count_vect.get_feature_names())\n","\n","print(count_vect.vocabulary_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['42', 'and', 'answer', 'cat', 'dreamer', 'hello', 'is', 'the', 'there', 'world']\n","{'hello': 5, 'there': 8, 'world': 9, 'is': 6, 'cat': 3, 'dreamer': 4, 'and': 1, 'the': 7, 'answer': 2, '42': 0}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"markdown","metadata":{"id":"zHJ1ZlL_Rk8b"},"source":["### Dealing with **stop words** in `CountVectorizer()`\n","- custom stop words list\n","- `sklearn`'s built in stop words list in English\n","- using `max_df` and `min_df`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9x_3FfRUGz0","executionInfo":{"status":"ok","timestamp":1637160484960,"user_tz":-540,"elapsed":355,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"a29392f1-106f-4b8a-fd02-c01d9c38a46f"},"source":["# Q3. Redo the above task by specifying \"a\" and \"the\" as stop words. Print out the document term matrix as before\n","count_vect = CountVectorizer(stop_words=[\"a\", \"the\"])\n","count_matrix = count_vect.fit_transform(corpus)\n","# Convert matrix to array\n","count_array = count_matrix.toarray()\n","# Convert array to data frame, dtm (document term matrix)\n","dtm = pd.DataFrame(data=count_array, \n","                   columns=count_vect.get_feature_names())\n","print(dtm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   42  and  answer  cat  dreamer  hello  is  there  world\n","0   0    0       0    0        0      1   0      1      1\n","1   0    0       0    1        0      0   1      1      0\n","2   0    0       0    0        1      0   0      0      0\n","3   0    0       0    1        1      0   0      2      0\n","4   1    1       1    0        0      0   1      0      0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9-F4Dp2UvhO","executionInfo":{"status":"ok","timestamp":1637160492081,"user_tz":-540,"elapsed":325,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"3514d209-04a9-4956-b935-72a0083880ef"},"source":["# Q4. Redo the above task by adding all known stop words in sklearn's built-in list in 'english'. \n","# Print out the document term matrix as before\n","\n","count_vect = CountVectorizer(stop_words='english')\n","count_matrix = count_vect.fit_transform(corpus)\n","# Convert matrix to array\n","count_array = count_matrix.toarray()\n","# Convert array to data frame, dtm (document term matrix)\n","dtm = pd.DataFrame(data=count_array, \n","                   columns=count_vect.get_feature_names())\n","print(dtm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   42  answer  cat  dreamer  hello  world\n","0   0       0    0        0      1      1\n","1   0       0    1        0      0      0\n","2   0       0    0        1      0      0\n","3   0       0    1        1      0      0\n","4   1       1    0        0      0      0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"HaqtCWKMVEK-"},"source":["# Q5. Which words were removed from the original list of words?\n","# 'and', 'is', 'there', 'hello'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0WSB4P2TZjgX","executionInfo":{"status":"ok","timestamp":1637160497716,"user_tz":-540,"elapsed":351,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"6542c4e1-cc0a-4c93-d7de-742859f9edf2"},"source":["# Q6. Remove any words that occur more than twice in the document and print out the document term matrix as before\n","count_vect = CountVectorizer(stop_words='english', max_df = 1)\n","count_matrix = count_vect.fit_transform(corpus)\n","# Convert matrix to array\n","count_array = count_matrix.toarray()\n","# Convert array to data frame, dtm (document term matrix)\n","dtm = pd.DataFrame(data=count_array, \n","                   columns=count_vect.get_feature_names())\n","print(dtm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   42  answer  hello  world\n","0   0       0      1      1\n","1   0       0      0      0\n","2   0       0      0      0\n","3   0       0      0      0\n","4   1       1      0      0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RM1pxgx5bJU_","executionInfo":{"status":"ok","timestamp":1637160507695,"user_tz":-540,"elapsed":348,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"b0a5c4c4-6646-41a2-80bc-2237c3f5a89b"},"source":["# Q7. Remove any words that occur in less than 20% of the document and print out the document term matrix as before\n","count_vect = CountVectorizer(stop_words='english', min_df = .2, max_df = 1)\n","count_matrix = count_vect.fit_transform(corpus)\n","# Convert matrix to array\n","count_array = count_matrix.toarray()\n","# Convert array to data frame, dtm (document term matrix)\n","dtm = pd.DataFrame(data=count_array, \n","                   columns=count_vect.get_feature_names())\n","print(dtm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   42  answer  hello  world\n","0   0       0      1      1\n","1   0       0      0      0\n","2   0       0      0      0\n","3   0       0      0      0\n","4   1       1      0      0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"CcvCUYvobljk"},"source":["# Q8. Which words were removed and why?\n","# 'cat, dreamer, is , there' are removed b/c they appeared more than twice in corpus "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9ePkDm6i8FL"},"source":["Use bigrams instead of single words\n","- specify the range of n-grams in the `ngram_range` argument in `CountVectorizer()`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9BwgGZXSh_uu","executionInfo":{"status":"ok","timestamp":1637160512780,"user_tz":-540,"elapsed":333,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"6996e731-99aa-451b-e76e-eebc92ddf581"},"source":["count_vect = CountVectorizer(ngram_range=(2,2))\n","count_matrix = count_vect.fit_transform(corpus)\n","count_array = count_matrix.toarray()\n","dtm = pd.DataFrame(data=count_array, columns=count_vect.get_feature_names())\n","print(dtm)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   and the  answer is  dreamer cat  ...  there is  there there  there world\n","0        0          0            0  ...         0            0            1\n","1        0          0            0  ...         1            0            0\n","2        0          0            0  ...         0            0            0\n","3        0          0            1  ...         0            1            0\n","4        1          1            0  ...         0            0            0\n","\n","[5 rows x 11 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqOUUXDokGmx","executionInfo":{"status":"ok","timestamp":1637160528940,"user_tz":-540,"elapsed":364,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"05d06f6b-ce49-4d4c-967b-7d287d45fca9"},"source":["# View the tokens in this vector\n","count_vect.get_feature_names()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["['and the',\n"," 'answer is',\n"," 'dreamer cat',\n"," 'hello there',\n"," 'is 42',\n"," 'is cat',\n"," 'the answer',\n"," 'there dreamer',\n"," 'there is',\n"," 'there there',\n"," 'there world']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZbX0AMzfiRIo","executionInfo":{"status":"ok","timestamp":1637160534133,"user_tz":-540,"elapsed":363,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"0b6a7e50-e4f3-4843-f7fe-3ef8b48a28ac"},"source":["# View the vocabulary of this vector\n","count_vect.vocabulary_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'and the': 0,\n"," 'answer is': 1,\n"," 'dreamer cat': 2,\n"," 'hello there': 3,\n"," 'is 42': 4,\n"," 'is cat': 5,\n"," 'the answer': 6,\n"," 'there dreamer': 7,\n"," 'there is': 8,\n"," 'there there': 9,\n"," 'there world': 10}"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvjaPW-kntqQ","executionInfo":{"status":"ok","timestamp":1637160538857,"user_tz":-540,"elapsed":370,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"315df281-1090-47e0-c538-ef5ec1431c5c"},"source":["# Q9. Redo the above task by using unigrams and bigrams and removing stop words from the built-in list in 'english' \n","# to build the vocabulary. Print out the document term matrix as before.\n","count_vect = CountVectorizer(ngram_range=(2,2), stop_words = 'english')\n","count_matrix = count_vect.fit_transform(corpus)\n","count_array = count_matrix.toarray()\n","dtm = pd.DataFrame(data=count_array, columns=count_vect.get_feature_names())\n","print(dtm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   answer 42  dreamer cat  hello world\n","0          0            0            1\n","1          0            0            0\n","2          0            0            0\n","3          0            1            0\n","4          1            0            0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKKq_xDinx5E","executionInfo":{"status":"ok","timestamp":1637160541435,"user_tz":-540,"elapsed":338,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"94579d3f-baa4-4c83-b393-d52ddb4a5406"},"source":["count_vect.vocabulary_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer 42': 0, 'dreamer cat': 1, 'hello world': 2}"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"6jPCTVhFYD5M"},"source":["Use the vocab created on the simple training data in Q9 above on a new sentence"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2gSSim_w5Sl","executionInfo":{"status":"ok","timestamp":1637160543759,"user_tz":-540,"elapsed":366,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"887dfac5-33e8-4e0a-e209-85a9316f75e4"},"source":["test = [\"The cat there is ginger\"]\n","result = count_vect.transform(test)\n","result.toarray()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0]])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1i6v_eGKvCo","executionInfo":{"status":"ok","timestamp":1637160550177,"user_tz":-540,"elapsed":331,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"f74e27b3-3398-44c8-f44f-29b742f01bf7"},"source":["# Run this code cell\n","count_vect.transform(['Something completely new.']).toarray()\n","\n","# Q10. Why is the result like so?\n","# Because the input sentence was not in the train corpus when fitting the countvectorizer.\n","# So, it returns all zero when using transform()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0]])"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"LIu4TkUs8Ndo"},"source":["# Lab 11: RNN Text Classification – Sentiment Analysis of IMDB Movie Reviews\n","- We will use Python `pandas` to read a csv file containing IMDB movie reviews available from a public Google drive folder\n","- We will train on the WHOLE dataset instead of splitting into train/test\n","- We will create a custom Dataset for the IMDB sequences\n","- We will use utilities from `torch.nn.utils.rnn` for padding\n","- We will use `scikit-learn.feature_extraction.text.CountVectorizer` to convert a collection of text documents to a matrix of token counts\n","- We will define a Recurrent Neural Network (RNN) that utilises GRUs\n","- We will use DataLoader to load the data in batches\n","- We will use `tqdm.notebook` utilities to add a progress bar when training\n","- We will test on existing reviews and any user provided review\n","- NOTE: Please connect to the GPU for this part"]},{"cell_type":"code","metadata":{"id":"yXDI3Zx40bvC","executionInfo":{"status":"ok","timestamp":1637165807640,"user_tz":-540,"elapsed":28060,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}}},"source":["from pathlib import Path\n","\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cz-5stSEbUzQ","executionInfo":{"status":"ok","timestamp":1637165807641,"user_tz":-540,"elapsed":11,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"f74cad14-2beb-4c25-ab3f-eae2fd0bab92"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"WX3lRr0HdN3V","executionInfo":{"status":"ok","timestamp":1637165808057,"user_tz":-540,"elapsed":422,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}}},"source":["rnn = nn.RNN(10, 20, num_layers=1, batch_first = True)\n","input = torch.randn(5, 3, 10)\n","h0 = torch.randn(1, 5, 20)\n","output, hn = rnn(input, h0)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bb_Esb5wdQIl","executionInfo":{"status":"ok","timestamp":1637162092035,"user_tz":-540,"elapsed":378,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"2900bd91-d95e-43dd-b5e5-d8bf2a5208ec"},"source":["hn"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.2776, -0.3898, -0.3477, -0.7287, -0.5467, -0.1012,  0.1068,\n","           0.3586, -0.3180,  0.4679, -0.2277, -0.6260, -0.1839,  0.0732,\n","          -0.0245,  0.3626,  0.7058, -0.6857,  0.6103,  0.0961],\n","         [-0.2908,  0.2967,  0.2647,  0.0625,  0.1686, -0.1000,  0.2750,\n","           0.1251, -0.4424,  0.0364, -0.1297, -0.1373,  0.7185,  0.5164,\n","          -0.2296,  0.5873, -0.0289, -0.4095,  0.0780,  0.0056],\n","         [-0.2568, -0.5083, -0.2744, -0.0622, -0.4209,  0.2349,  0.1153,\n","          -0.7086,  0.4215,  0.3604, -0.4248, -0.5540, -0.8335, -0.6231,\n","           0.4613, -0.3617,  0.5296, -0.4874,  0.6773,  0.5507],\n","         [ 0.1393,  0.7038, -0.4353, -0.3602, -0.5948, -0.1184,  0.7826,\n","           0.2972, -0.8461,  0.5251,  0.5122,  0.8242,  0.7768, -0.2055,\n","          -0.7158,  0.8799, -0.5458, -0.4814, -0.7184,  0.2695],\n","         [-0.3855, -0.2546,  0.4007, -0.0686, -0.7233, -0.7416,  0.3593,\n","          -0.9250,  0.8546,  0.3272, -0.7286, -0.2423,  0.1581, -0.3639,\n","           0.8682,  0.0380,  0.5132,  0.0439,  0.8533,  0.6705]]],\n","       grad_fn=<StackBackward0>)"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"r3ACuac9H6e0"},"source":["## Download the training data\n","\n","This is a dataset of positive and negative IMDB reviews. We can download the data from a public Google Drive folder by providing a id of the sharable link from Google Drive and a destination path."]},{"cell_type":"code","metadata":{"id":"HygBcmu9YqZY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637165819701,"user_tz":-540,"elapsed":8087,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"d2a78ad2-0485-4311-e994-6d9536570c62"},"source":["DATA_PATH = 'data/imdb_reviews.csv'\n","if not Path(DATA_PATH).is_file():\n","    gdd.download_file_from_google_drive(\n","        file_id='1zfM5E6HvKIe7f3rEt1V2gBpw5QOSSKQz',\n","        dest_path=DATA_PATH,\n","    )\n","\n","# Q11. Where is the csv file saved?\n","# /content/data/imdb_reviews.csv"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading 1zfM5E6HvKIe7f3rEt1V2gBpw5QOSSKQz into data/imdb_reviews.csv... Done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"nmNt55pgKIDa"},"source":["## Preprocess the text\n","- create a custom Dataset class for this data which takes in a maximum length for the sequence\n","  - `__init__(), __len__(), __getitem__()`\n","  - contains vocab, encode pad and sequences attributes\n","- read the CSV file using pandas\n","- tokenizing strings and giving an integer id for each possible token, for instance by using white-spaces and punctuation as token separators\n","- add padding"]},{"cell_type":"code","metadata":{"id":"jvHQmJZQB2gQ","executionInfo":{"status":"ok","timestamp":1637165819701,"user_tz":-540,"elapsed":5,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}}},"source":["class IMDB_sequence(Dataset):\n","    def __init__(self, path, max_seq_len):\n","        self.max_seq_len = max_seq_len\n","        df = pd.read_csv(path)\n","        # Print the first ten lines\n","        print(df.head(10))\n","        # Data shape\n","        print(df.shape)\n","\n","        # Use CountVectorizer()\n","        vectorizer = CountVectorizer(stop_words='english', min_df=0.015)\n","        vectorizer.fit(df.review.tolist())\n","        \n","        self.vocab = vectorizer.vocabulary_\n","        # Add padding token\n","        self.vocab['<PAD>'] = max(self.vocab.values()) + 1\n","\n","        # Create a tokenizer instance that lets you extract the tokenizing step from the pipeline wrapped in CountVectorizer  \n","        tokenizer = vectorizer.build_tokenizer()\n","        self.encode = lambda x: [self.vocab[token] for token in tokenizer(x)\n","                                 if token in self.vocab]\n","        self.pad = lambda x: x + (max_seq_len - len(x)) * [self.vocab['<PAD>']]\n","        \n","        # Get sequence from each row and prepare it to have length max_seq_len\n","        sequences = [self.encode(sequence)[:max_seq_len] for sequence in df.review.tolist()]\n","        sequences, self.labels = zip(*[(sequence, label) for sequence, label\n","                                    in zip(sequences, df.label.tolist()) if sequence])\n","        self.sequences = [self.pad(sequence) for sequence in sequences]\n","\n","    def __getitem__(self, i):\n","        assert len(self.sequences[i]) == self.max_seq_len\n","        return self.sequences[i], self.labels[i]\n","    \n","    def __len__(self):\n","        return len(self.sequences)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"rUMfy9ahe2LM"},"source":["# Q12. Why is fit() and not fit_transform() used here?\n","# B/c they are gonna be used as train set\n","\n","# Q13. What would happen to reviews that are made up of more than max_seq_len tokens?\n","# Show which line(s) of code handles this.\n","# self.pad = lambda x: x + (max_seq_len - len(x)) * [self.vocab['<PAD>']]\n","# All tokens which exceed the max_seq_len would be <PAD>\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmj-NjyaZ0vi"},"source":["### Create Dataset Instance"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9lOkmrQKOkYQ","executionInfo":{"status":"ok","timestamp":1637165853190,"user_tz":-540,"elapsed":19603,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"904be04e-0d54-4531-b794-2647ce15231e"},"source":["# This could take a little while (20-30 secs)\n","dataset = IMDB_sequence(DATA_PATH, max_seq_len=128)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["                                              review  label\n","0  Once again Mr. Costner has dragged out a movie...      0\n","1  This is an example of why the majority of acti...      0\n","2  First of all I hate those moronic rappers, who...      0\n","3  Not even the Beatles could write songs everyon...      0\n","4  Brass pictures (movies is not a fitting word f...      0\n","5  A funny thing happened to me while watching \"M...      0\n","6  This German horror film has to be one of the w...      0\n","7  Being a long-time fan of Japanese film, I expe...      0\n","8  \"Tokyo Eyes\" tells of a 17 year old Japanese g...      0\n","9  Wealthy horse ranchers in Buenos Aires have a ...      0\n","(62155, 2)\n"]}]},{"cell_type":"code","metadata":{"id":"2EDNLfZug4qa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKqXlxmvgDVo"},"source":["next(iter(dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0n0mbdU_knd"},"source":["# Q14. How many rows and columns are there in this dataset? What do the columns represent?\n","# There are 62155 rows (=reviews) in dataset and 2 columns.\n","# First column represents the each review, second is sentimental label."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikzeFTBcOkYR","executionInfo":{"status":"ok","timestamp":1637159117012,"user_tz":-540,"elapsed":14,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"7312d41a-fe20-478d-8e5d-aa828054ef32"},"source":["print(len(dataset.vocab))\n","\n","# Q15. How many unique words have been extracted from this dataset to build the vocabulary?\n","# 1104"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1104\n"]}]},{"cell_type":"markdown","metadata":{"id":"I0qx2IsXYli-"},"source":["### Custom Collate Function & DataLoader\n","- Convert reviews and labels to tensors"]},{"cell_type":"code","metadata":{"id":"2YcDPSgKIgcm","executionInfo":{"status":"ok","timestamp":1637165862566,"user_tz":-540,"elapsed":623,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}}},"source":["def collate(batch):\n","    inputs = torch.LongTensor([item[0] for item in batch])\n","    target = torch.FloatTensor([item[1] for item in batch])\n","    return inputs, target\n","\n","batch_size = 2048\n","train_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nk9kCFx5REhk"},"source":["### Create RNN class"]},{"cell_type":"code","metadata":{"id":"ARBIogVSNWog","executionInfo":{"status":"ok","timestamp":1637165866054,"user_tz":-540,"elapsed":853,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}}},"source":["class RNN_sentiment(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        batch_size,\n","        embedding_dimension=100,\n","        hidden_size=128, \n","        num_layers=1,\n","        device='cpu',\n","    ):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size # number of features in the hidden state h\n","        self.device = device\n","        self.batch_size = batch_size\n","        \n","        self.encoder = nn.Embedding(vocab_size, embedding_dimension)\n","        self.rnn = nn.RNN(\n","            embedding_dimension,\n","            hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True, # provide input and output tensors as (batch, seq, hidden_size)\n","        )\n","        self.decoder = nn.Linear(hidden_size, 1)\n","        \n","    def init_hidden(self):\n","        # return torch.randn(self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n","        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n","    \n","    def forward(self, inputs):\n","        # Avoid breaking if the last batch has a different size\n","        batch_size = inputs.size(0)\n","        if batch_size != self.batch_size:\n","            self.batch_size = batch_size\n","            \n","        encoded = self.encoder(inputs)\n","        output, hidden = self.rnn(encoded, self.init_hidden())\n","        # output[batch_size, seq, hidden_size]\n","        # Take all from batch and seq but only output from last layer\n","        output = self.decoder(output[:, :, -1]).squeeze()\n","        return output\n","\n","# Q15. Why does the decoder layer have an output size of 1?\n","# It should return binary ; Positive/Negative label "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kIzJ2mFGPMAs","executionInfo":{"status":"ok","timestamp":1637165869304,"user_tz":-540,"elapsed":835,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"91a72ab1-ff13-446e-9fdf-765002808c88"},"source":["model = RNN_sentiment(\n","    hidden_size=128,\n","    vocab_size=len(dataset.vocab),\n","    device=device,\n","    batch_size=batch_size,\n",")\n","model = model.to(device)\n","model"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNN_sentiment(\n","  (encoder): Embedding(1104, 100)\n","  (rnn): RNN(100, 128, batch_first=True)\n","  (decoder): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"nOnMEFTlc_N2"},"source":["### Loss and Optimiser\n","- `BCEWithLogitsLoss()` combines a Sigmoid layer and the BCELoss (Binary Cross Entropy Loss) in one single class\n","- **Logits** are unscaled (unnormalised) outputs of the model. It means, in particular, the sum of these outputs may not equal 1, or the values are not probabilities."]},{"cell_type":"code","metadata":{"id":"nkojdeZgWqtX","executionInfo":{"status":"ok","timestamp":1637165872548,"user_tz":-540,"elapsed":228,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}}},"source":["criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Rfai74aG0wh"},"source":["## Train the model\n","- Add a progress bar by using utilities from `tqdm.notebook`\n","- Add gradient clipping\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72,"referenced_widgets":["9800898548154e8f9f89ed5c5655bae7","ca36eefa91e44d73b6db520a64ae3876","36de6a8031a64d87b7c214fdd523fa64","b3aa84681ee14afaa951189a321e916a","4220c3771ee946ca93cacfa068384958","8d72e02b8a844919b58d0f6c2a54bd51","f04eb559cb0145a3a88a6692dadbb5bc","0bdffd4e7fee43129a59c21603b6a73d","e178607365ca41cd89961a88f43e6f90","5b353ec9114a44e5b3cbcfa8b1ec5eb7","e8a728c9f1294be89560685294009c19","55957763cfee48e880999df6f704c737","19b6d406277e4e4681c127ca2dcc6bca","1e18a34fe3014ff09189a55c10cc0d0b","e3d050c07d53432299b306bd55efcb0e","7570ff4372bd4ea9a0d29108e4fb4ce2","c11ebc23abe747d4aba838e94bd88cb2","636542f0f94045bea2d58aa8f4abb31b","a6b0b3e9580e42e5bedc2eacc6561405","5a13b9dfd8c6404ebe0d1d1a3af79f3f","30bf739a33b348e182a8aeac6b8b0844","4ca7759262674824a5a8a35fb8cabab8","54c6ad8c096a467a998384d004d82248","600d670a56e847fb91cfd745ed0349ce","28231e2667034f389ac51281dfd6d146","b18ed2bc32c245158253dcbb9a75fbd0","b504dbbcf6d64425a4935ba4e9bd0cd1","c9b9485fb96348d39dbef54eec004000","813c0c74d4e042fdbe7a7b6bb216df96","2fdb294e1c4d42a797ed6c23bab36109","1babf6c62a1542da8cb1d53b731c4882","eaff0af0703149c294e0d29673eac072","fae169a289224a999c6c1812d414297c"]},"id":"3p-zmPJdOkYT","executionInfo":{"status":"ok","timestamp":1637166111118,"user_tz":-540,"elapsed":157613,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"499cfc25-71e3-4329-cfe9-483cb9b7047c"},"source":["from tqdm.notebook import tqdm, tqdm_notebook\n","\n","EPOCHS = 3\n","\n","model.train()\n","train_losses = []\n","for epoch in range(EPOCHS):\n","    progress_bar = tqdm_notebook(train_loader, leave=False)\n","    losses = []\n","    total = 0\n","    for inputs, target in progress_bar:\n","        inputs, target = inputs.to(device), target.to(device)\n","\n","        model.zero_grad()\n","\n","        output = model(inputs)\n","    \n","        loss = criterion(output, target)\n","        \n","        loss.backward()\n","              \n","        nn.utils.clip_grad_norm_(model.parameters(), 3)\n","\n","        optimizer.step()\n","        \n","        progress_bar.set_description(f'Epoch {epoch+1} Loss: {loss.item():.4f}')\n","        \n","        losses.append(loss.item())\n","        total += 1\n","    \n","    epoch_loss = sum(losses) / total\n","    train_losses.append(epoch_loss)\n","\n","    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9800898548154e8f9f89ed5c5655bae7","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/31 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch #1\tTrain Loss: 0.729\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55957763cfee48e880999df6f704c737","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/31 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch #2\tTrain Loss: 0.718\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54c6ad8c096a467a998384d004d82248","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/31 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch #3\tTrain Loss: 0.711\n"]}]},{"cell_type":"code","metadata":{"id":"--P45eFIzSm4"},"source":["# Q16. Explain what this line of code in the training loop is doing and why is it needed:\n","#nn.utils.clip_grad_norm_(model.parameters(), 3)\n","# It clips the gradient not to be exploded, that is, it prevents the gradient exploding."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RWYKZxi-IPKn"},"source":["### Test the Model\n","- `predict_sentiment` function takes in a piece of text and determines if it is positive or negative based on what it has learned from the training data"]},{"cell_type":"code","metadata":{"id":"4CpZARwhQFSf","executionInfo":{"status":"ok","timestamp":1637166111118,"user_tz":-540,"elapsed":4,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}}},"source":["def predict_sentiment(text):\n","    model.eval()\n","    with torch.no_grad():\n","        # Encode, pad and convert to tensor\n","        test_vector = torch.LongTensor([dataset.pad(dataset.encode(text))]).to(device)\n","        \n","        output = model(test_vector)\n","        prediction = torch.sigmoid(output).item()\n","\n","        if prediction > 0.5:\n","            print(f'{prediction:0.3f}: Positive sentiment')\n","        else:\n","            print(f'{prediction:0.3f}: Negative sentiment')\n","\n","# Q17. Why do we need to run the sigmoid function (torch.sigmoid) on the predictions?\n","# We need to classify the review's sentiment (pos/neg)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PavGV8xFV0Ve"},"source":["### Test on Reviews from \"Cool Cat Saves the Kids\" using Trained RNN:\n","\n","![](https://m.media-amazon.com/images/M/MV5BNzE1OTY3OTk5M15BMl5BanBnXkFtZTgwODE0Mjc1NDE@._V1_UY268_CR11,0,182,268_AL_.jpg)\n","\n","Run the following code cells to see how well the model can tell apart positive reviews from negative ones"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3O-UyplvcCY-","executionInfo":{"status":"ok","timestamp":1637166111870,"user_tz":-540,"elapsed":8,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"7f0a2139-c13d-4e7b-f5a9-748082fb9152"},"source":["test_text = \"\"\"\n","This poor excuse for a movie is terrible. It has been 'so good it's bad' for a\n","while, and the high ratings are a good form of sarcasm, I have to admit. But\n","now it has to stop. Technically inept, spoon-feeding mundane messages with the\n","artistic weight of an eighties' commercial, hypocritical to say the least, it\n","deserves to fall into oblivion. Mr. Derek, I hope you realize you are like that\n","weird friend that everybody know is lame, but out of kindness and Christian\n","duty is treated like he's cool or something. That works if you are a good\n","decent human being, not if you are a horrible arrogant bully like you are. Yes,\n","Mr. 'Daddy' Derek will end on the history books of the internet for being a\n","delusional sour old man who thinks to be a good example for kids, but actually\n","has a poster of Kim Jong-Un in his closet. Destroy this movie if you all have a\n","conscience, as I hope IHE and all other youtube channel force-closed by Derek\n","out of SPITE would destroy him in the courts.This poor excuse for a movie is\n","terrible. It has been 'so good it's bad' for a while, and the high ratings are\n","a good form of sarcasm, I have to admit. But now it has to stop. Technically\n","inept, spoon-feeding mundane messages with the artistic weight of an eighties'\n","commercial, hypocritical to say the least, it deserves to fall into oblivion.\n","Mr. Derek, I hope you realize you are like that weird friend that everybody\n","know is lame, but out of kindness and Christian duty is treated like he's cool\n","or something. That works if you are a good decent human being, not if you are a\n","horrible arrogant bully like you are. Yes, Mr. 'Daddy' Derek will end on the\n","history books of the internet for being a delusional sour old man who thinks to\n","be a good example for kids, but actually has a poster of Kim Jong-Un in his\n","closet. Destroy this movie if you all have a conscience, as I hope IHE and all\n","other youtube channel force-closed by Derek out of SPITE would destroy him in\n","the courts.\n","\"\"\"\n","predict_sentiment(test_text) # Ground truth: Negative"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["0.687: Positive sentiment\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IuEaKJxOkYU","executionInfo":{"status":"ok","timestamp":1637166111871,"user_tz":-540,"elapsed":6,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"24c19719-ace8-46c5-eaa3-a3927c95ce13"},"source":["test_text = \"\"\"\n","Cool Cat Saves The Kids is a symbolic masterpiece directed by Derek Savage that\n","is not only satirical in the way it makes fun of the media and politics, but in\n","the way in questions as how we humans live life and how society tells us to\n","live life.\n","\n","Before I get into those details, I wanna talk about the special effects in this\n","film. They are ASTONISHING, and it shocks me that Cool Cat Saves The Kids got\n","snubbed by the Oscars for Best Special Effects. This film makes 2001 look like\n","garbage, and the directing in this film makes Stanley Kubrick look like the\n","worst director ever. You know what other film did that? Birdemic: Shock and\n","Terror. Both of these films are masterpieces, but if I had to choose my\n","favorite out of the 2, I would have to go with Cool Cat Saves The Kids. It is\n","now my 10th favorite film of all time.\n","\n","Now, lets get into the symbolism: So you might be asking yourself, Why is Cool\n","Cat Orange? Well, I can easily explain. Orange is a color. Orange is also a\n","fruit, and its a very good fruit. You know what else is good? Good behavior.\n","What behavior does Cool Cat have? He has good behavior. This cannot be a\n","coincidence, since cool cat has good behavior in the film.\n","\n","Now, why is Butch The Bully fat? Well, fat means your wide. You wanna know who\n","was wide? Hitler. Nuff said this cannot be a coincidence.\n","\n","Why does Erik Estrada suspect Butch The Bully to be a bully? Well look at it\n","this way. What color of a shirt was Butchy wearing when he walks into the area?\n","I don't know, its looks like dark purple/dark blue. Why rhymes with dark? Mark.\n","Mark is that guy from the Room. The Room is the best movie of all time. What is\n","the opposite of best? Worst. This is how Erik knew Butch was a bully.\n","\n","and finally, how come Vivica A. Fox isn't having a successful career after\n","making Kill Bill.\n","\n","I actually can't answer that question.\n","\n","Well thanks for reading my review.\n","\"\"\"\n","predict_sentiment(test_text) # Ground truth: Positive"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0.497: Negative sentiment\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYsjklf3OkYV","executionInfo":{"status":"ok","timestamp":1637166111871,"user_tz":-540,"elapsed":4,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"4bd1fee9-8c16-4b5a-e614-28c8fe4c36f8"},"source":["test_text = \"\"\"\n","Don't let any bullies out there try and shape your judgment on this gem of a\n","title.\n","\n","Some people really don't have anything better to do, except trash a great movie\n","with annoying 1-star votes and spread lies on the Internet about how \"dumb\"\n","Cool Cat is.\n","\n","I wouldn't be surprised to learn if much of the unwarranted negativity hurled\n","at this movie is coming from people who haven't even watched this movie for\n","themselves in the first place. Those people are no worse than the Butch the\n","Bully, the film's repulsive antagonist.\n","\n","As it just so happens, one of the main points of \"Cool Cat Saves the Kids\" is\n","in addressing the attitudes of mean naysayers who try to demean others who\n","strive to bring good attitudes and fun vibes into people's lives. The message\n","to be learned here is that if one is friendly and good to others, the world is\n","friendly and good to one in return, and that is cool. Conversely, if one is\n","miserable and leaving 1-star votes on IMDb, one is alone and doesn't have any\n","friends at all. Ain't that the truth?\n","\n","The world has uncovered a great, new, young filmmaking talent in \"Cool Cat\"\n","creator Derek Savage, and I sure hope that this is only the first of many\n","amazing films and stories that the world has yet to appreciate.\n","\n","If you are a cool person who likes to have lots of fun, I guarantee that this\n","is a movie with charm that will uplift your spirits and reaffirm your positive\n","attitudes towards life.\n","\"\"\"\n","predict_sentiment(test_text) # Ground truth: Positive"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["0.408: Negative sentiment\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWLkSsOHOkYV","executionInfo":{"status":"ok","timestamp":1636990494473,"user_tz":-540,"elapsed":8,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"9aa00b3c-9b81-41af-f728-c476e6b39bbc"},"source":["tricky_test = \"\"\"\n","It is not a great movie to be honest. \n","I wish it was a bit longer with more plot twists.\n","The characters were not well developed. \n","I will not be seeing the sequel. \n","\"\"\"\n","\n","predict_sentiment(tricky_test) # Ground truth: Negative"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.840: Positive sentiment\n"]}]},{"cell_type":"markdown","metadata":{"id":"eAUpWMNCjh9A"},"source":["### Test with your own sentiments!\n","\n","### Improve the model above by one or more of the following:\n","- Increasing `num_layers` to 2 (stacking two RNNs instead of 1)\n","- Initialising h0 to random values rather than 0s (code line provided as a comment in RNN_sentiment()\n","- Using a GRU layer instead of a vanilla RNN\n","- Using bigrams (or unigrams and bigrams) instead of just single words when creating the vocabulary\n","- Using an LSTM layer instead of vanilla RNN/GRU (add your own LSTM class and create an instance)\n","- Anything else you can think of\n","- **NOTE:** You MUST run predict_sentiment() after training your model and before testing with the test texts each time\n","- **NOTE:** Train for about 30-50 epochs (max 80) to save time and GPU limit\n"]},{"cell_type":"code","metadata":{"id":"f4ycY_ytLU6P"},"source":["class GRU_sentiment(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        batch_size,\n","        embedding_dimension=100,\n","        hidden_size=128, \n","        num_layers=1,\n","        device='cpu',\n","    ):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size # number of features in the hidden state h\n","        self.device = device\n","        self.batch_size = batch_size\n","        \n","        self.encoder = nn.Embedding(vocab_size, embedding_dimension)\n","        self.gru = nn.GRU(\n","            embedding_dimension,\n","            hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True, # provide input and output tensors as (batch, seq, hidden_size)\n","        )\n","        self.decoder = nn.Linear(hidden_size, 1)\n","        \n","    def init_hidden(self):\n","        # return torch.randn(self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n","        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n","    \n","    def forward(self, inputs):\n","        # Avoid breaking if the last batch has a different size\n","        batch_size = inputs.size(0)\n","        if batch_size != self.batch_size:\n","            self.batch_size = batch_size\n","            \n","        encoded = self.encoder(inputs)\n","        output, hidden = self.gru(encoded, self.init_hidden())\n","        # output[batch_size, seq, hidden_size]\n","        # Take all from batch and seq but only output from last layer\n","        output = self.decoder(output[:, :, -1]).squeeze()\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2grCXF54yUw1"},"source":["class IMDB_sequence(Dataset):\n","    def __init__(self, path, max_seq_len):\n","        self.max_seq_len = max_seq_len\n","        df = pd.read_csv(path)\n","        # Print the first ten lines\n","        print(df.head(10))\n","        # Data shape\n","        print(df.shape)\n","\n","        # Use CountVectorizer()\n","        vectorizer = CountVectorizer(stop_words='english', min_df=0.015, )\n","        vectorizer.fit(df.review.tolist())\n","        \n","        self.vocab = vectorizer.vocabulary_\n","        # Add padding token\n","        self.vocab['<PAD>'] = max(self.vocab.values()) + 1\n","\n","        # Create a tokenizer instance that lets you extract the tokenizing step from the pipeline wrapped in CountVectorizer  \n","        tokenizer = vectorizer.build_tokenizer()\n","        self.encode = lambda x: [self.vocab[token] for token in tokenizer(x)\n","                                 if token in self.vocab]\n","        self.pad = lambda x: x + (max_seq_len - len(x)) * [self.vocab['<PAD>']]\n","        \n","        # Get sequence from each row and prepare it to have length max_seq_len\n","        sequences = [self.encode(sequence)[:max_seq_len] for sequence in df.review.tolist()]\n","        sequences, self.labels = zip(*[(sequence, label) for sequence, label\n","                                    in zip(sequences, df.label.tolist()) if sequence])\n","        self.sequences = [self.pad(sequence) for sequence in sequences]\n","\n","    def __getitem__(self, i):\n","        assert len(self.sequences[i]) == self.max_seq_len\n","        return self.sequences[i], self.labels[i]\n","    \n","    def __len__(self):\n","        return len(self.sequences)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZkRnGEftMcY","executionInfo":{"status":"ok","timestamp":1637166679191,"user_tz":-540,"elapsed":2,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}}},"source":["class LSTM_sentiment(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        batch_size,\n","        embedding_dimension=100,\n","        hidden_size=128, \n","        num_layers=1,\n","        device='cpu',\n","    ):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size # number of features in the hidden state h\n","        self.device = device\n","        self.batch_size = batch_size\n","        \n","        self.encoder = nn.Embedding(vocab_size, embedding_dimension)\n","        self.lstm = nn.LSTM(\n","            embedding_dimension,\n","            hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True, # provide input and output tensors as (batch, seq, hidden_size)\n","        )\n","        self.decoder = nn.Linear(hidden_size, 1)\n","        \n","    \n","    def forward(self, inputs):\n","        # Avoid breaking if the last batch has a different size\n","        batch_size = inputs.size(0)\n","        if batch_size != self.batch_size:\n","            self.batch_size = batch_size\n","        \n","        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n","        c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n","            \n","        encoded = self.encoder(inputs)\n","        output, (hn, cn) = self.lstm(encoded, (h_0, c_0))\n","        # output[batch_size, seq, hidden_size]\n","        # Take all from batch and seq but only output from last layer\n","        output = self.decoder(output[:, :, -1]).squeeze()\n","        return output"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-fxUKAnLbp-","executionInfo":{"status":"ok","timestamp":1637166684956,"user_tz":-540,"elapsed":246,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"b8043de3-3afd-4e76-b2f9-cb53203b8e4f"},"source":["model = LSTM_sentiment(\n","    hidden_size=128,\n","    vocab_size=len(dataset.vocab),\n","    device=device,\n","    batch_size=batch_size,\n",")\n","model = model.to(device)\n","model"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM_sentiment(\n","  (encoder): Embedding(1104, 100)\n","  (lstm): LSTM(100, 128, batch_first=True)\n","  (decoder): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"jcU5z_xXLbp_","executionInfo":{"status":"ok","timestamp":1637166687977,"user_tz":-540,"elapsed":271,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}}},"source":["criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72,"referenced_widgets":["f3a69e764a3f41d188fab7dabdf38894","ef5e176d3d9743e081552827d8353722","544cb1d3971c46f79beecddc02470e37","d0f398fa0be24debb7d40bd77c3558d0","0ed2c1f79f474ba8ac85966ce62a2388","921495eae30a4726b781bac0dae2b959","3b563fb7ec874809b9b2e321ac3cf6a8","fc7c03c6744d4b869c5301f168ebc8e0","c6b736234db247e7b05bb57088cb76d2","d92a171c7f7e4d1296531ed648c157bd","ee6a57a1d444487e97c4c58f097aa098","915e0717f6ea43eda546f684fecebc38","1be00d580070428d9e967b15f079b078","9711566fff0b408abd42fb3de1facf3a","553dde379612407f93c75593b572ac53","628d086cff704f09b5eafb79e960ae22","8af88be225b84fb9b0e08233dc182b36","9a6b0508d15649c292b6ed8614081a37","58d5325d5d6c43edad7197874d87b175","37cb57eb8fc244e99e42b4facce4c8b5","173a1b7236f84e1a92dad447db7cbd10","8b02287ce8714e02b9507284475933d0","c7ba090d9f8842199b133180238a8610","ba8968d0265541809daa9eb2b597731c","98862015c7244e91a3521778059d2f90","de83f125bb5049baa9b897fc3dff2bf0","7a9dd3b606474b99a772da2235b8a316","ea5d56cc5b82480da9a46c9611d33a87","20cce72dd1f44ebdb4cda0f28e6c8371","0be1db1aa9f3440e98f33b89a064a10c","30f0400023844543a83f8cfa9c08ec86","d3cdcc1995b64496b4cadbbeaa5d32f7","bf4b6b06a79f4bd79570586b78dee010"]},"id":"6403rrUALbp_","executionInfo":{"status":"ok","timestamp":1637167241473,"user_tz":-540,"elapsed":548262,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"b61297a5-5e1f-48ef-eec9-c4b27cb639a0"},"source":["from tqdm.notebook import tqdm, tqdm_notebook\n","\n","EPOCHS = 3\n","\n","model.train()\n","train_losses = []\n","for epoch in range(EPOCHS):\n","    progress_bar = tqdm_notebook(train_loader, leave=False)\n","    losses = []\n","    total = 0\n","    for inputs, target in progress_bar:\n","        inputs, target = inputs.to(device), target.to(device)\n","\n","        model.zero_grad()\n","\n","        output = model(inputs)\n","    \n","        loss = criterion(output, target)\n","        \n","        loss.backward()\n","              \n","        nn.utils.clip_grad_norm_(model.parameters(), 3)\n","\n","        optimizer.step()\n","        \n","        progress_bar.set_description(f'Epoch {epoch+1} Loss: {loss.item():.4f}')\n","        \n","        losses.append(loss.item())\n","        total += 1\n","    \n","    epoch_loss = sum(losses) / total\n","    train_losses.append(epoch_loss)\n","\n","    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3a69e764a3f41d188fab7dabdf38894","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/31 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch #1\tTrain Loss: 0.756\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"915e0717f6ea43eda546f684fecebc38","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/31 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch #2\tTrain Loss: 0.698\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7ba090d9f8842199b133180238a8610","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/31 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch #3\tTrain Loss: 0.695\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMCiUn5qMWec","executionInfo":{"status":"ok","timestamp":1637159467970,"user_tz":-540,"elapsed":329,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"d3be3852-0359-49ee-8757-309ec6078082"},"source":["test_text = \"\"\"\n","This poor excuse for a movie is terrible. It has been 'so good it's bad' for a\n","while, and the high ratings are a good form of sarcasm, I have to admit. But\n","now it has to stop. Technically inept, spoon-feeding mundane messages with the\n","artistic weight of an eighties' commercial, hypocritical to say the least, it\n","deserves to fall into oblivion. Mr. Derek, I hope you realize you are like that\n","weird friend that everybody know is lame, but out of kindness and Christian\n","duty is treated like he's cool or something. That works if you are a good\n","decent human being, not if you are a horrible arrogant bully like you are. Yes,\n","Mr. 'Daddy' Derek will end on the history books of the internet for being a\n","delusional sour old man who thinks to be a good example for kids, but actually\n","has a poster of Kim Jong-Un in his closet. Destroy this movie if you all have a\n","conscience, as I hope IHE and all other youtube channel force-closed by Derek\n","out of SPITE would destroy him in the courts.This poor excuse for a movie is\n","terrible. It has been 'so good it's bad' for a while, and the high ratings are\n","a good form of sarcasm, I have to admit. But now it has to stop. Technically\n","inept, spoon-feeding mundane messages with the artistic weight of an eighties'\n","commercial, hypocritical to say the least, it deserves to fall into oblivion.\n","Mr. Derek, I hope you realize you are like that weird friend that everybody\n","know is lame, but out of kindness and Christian duty is treated like he's cool\n","or something. That works if you are a good decent human being, not if you are a\n","horrible arrogant bully like you are. Yes, Mr. 'Daddy' Derek will end on the\n","history books of the internet for being a delusional sour old man who thinks to\n","be a good example for kids, but actually has a poster of Kim Jong-Un in his\n","closet. Destroy this movie if you all have a conscience, as I hope IHE and all\n","other youtube channel force-closed by Derek out of SPITE would destroy him in\n","the courts.\n","\"\"\"\n","predict_sentiment(test_text) # Ground truth: Negative"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.002: Negative sentiment\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPxRG5n1MWec","executionInfo":{"status":"ok","timestamp":1637040245954,"user_tz":-540,"elapsed":7,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"4de46796-7535-4f08-c235-4b9af55be348"},"source":["test_text = \"\"\"\n","Cool Cat Saves The Kids is a symbolic masterpiece directed by Derek Savage that\n","is not only satirical in the way it makes fun of the media and politics, but in\n","the way in questions as how we humans live life and how society tells us to\n","live life.\n","\n","Before I get into those details, I wanna talk about the special effects in this\n","film. They are ASTONISHING, and it shocks me that Cool Cat Saves The Kids got\n","snubbed by the Oscars for Best Special Effects. This film makes 2001 look like\n","garbage, and the directing in this film makes Stanley Kubrick look like the\n","worst director ever. You know what other film did that? Birdemic: Shock and\n","Terror. Both of these films are masterpieces, but if I had to choose my\n","favorite out of the 2, I would have to go with Cool Cat Saves The Kids. It is\n","now my 10th favorite film of all time.\n","\n","Now, lets get into the symbolism: So you might be asking yourself, Why is Cool\n","Cat Orange? Well, I can easily explain. Orange is a color. Orange is also a\n","fruit, and its a very good fruit. You know what else is good? Good behavior.\n","What behavior does Cool Cat have? He has good behavior. This cannot be a\n","coincidence, since cool cat has good behavior in the film.\n","\n","Now, why is Butch The Bully fat? Well, fat means your wide. You wanna know who\n","was wide? Hitler. Nuff said this cannot be a coincidence.\n","\n","Why does Erik Estrada suspect Butch The Bully to be a bully? Well look at it\n","this way. What color of a shirt was Butchy wearing when he walks into the area?\n","I don't know, its looks like dark purple/dark blue. Why rhymes with dark? Mark.\n","Mark is that guy from the Room. The Room is the best movie of all time. What is\n","the opposite of best? Worst. This is how Erik knew Butch was a bully.\n","\n","and finally, how come Vivica A. Fox isn't having a successful career after\n","making Kill Bill.\n","\n","I actually can't answer that question.\n","\n","Well thanks for reading my review.\n","\"\"\"\n","predict_sentiment(test_text) # Ground truth: Positive"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.932: Positive sentiment\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWE4g6GcMWec","executionInfo":{"status":"ok","timestamp":1637040248729,"user_tz":-540,"elapsed":546,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"25b0f7af-f946-4d64-f74e-9ffbc347988e"},"source":["test_text = \"\"\"\n","Don't let any bullies out there try and shape your judgment on this gem of a\n","title.\n","\n","Some people really don't have anything better to do, except trash a great movie\n","with annoying 1-star votes and spread lies on the Internet about how \"dumb\"\n","Cool Cat is.\n","\n","I wouldn't be surprised to learn if much of the unwarranted negativity hurled\n","at this movie is coming from people who haven't even watched this movie for\n","themselves in the first place. Those people are no worse than the Butch the\n","Bully, the film's repulsive antagonist.\n","\n","As it just so happens, one of the main points of \"Cool Cat Saves the Kids\" is\n","in addressing the attitudes of mean naysayers who try to demean others who\n","strive to bring good attitudes and fun vibes into people's lives. The message\n","to be learned here is that if one is friendly and good to others, the world is\n","friendly and good to one in return, and that is cool. Conversely, if one is\n","miserable and leaving 1-star votes on IMDb, one is alone and doesn't have any\n","friends at all. Ain't that the truth?\n","\n","The world has uncovered a great, new, young filmmaking talent in \"Cool Cat\"\n","creator Derek Savage, and I sure hope that this is only the first of many\n","amazing films and stories that the world has yet to appreciate.\n","\n","If you are a cool person who likes to have lots of fun, I guarantee that this\n","is a movie with charm that will uplift your spirits and reaffirm your positive\n","attitudes towards life.\n","\"\"\"\n","predict_sentiment(test_text) # Ground truth: Positive"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.891: Positive sentiment\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JfhMequHMWed","executionInfo":{"status":"ok","timestamp":1637159472177,"user_tz":-540,"elapsed":218,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"d4f0aa57-4daa-4e18-a826-ddf8e7729509"},"source":["tricky_test = \"\"\"\n","It is not a great movie to be honest. \n","I wish it was a bit longer with more plot twists.\n","The characters were not well developed. \n","I will not be seeing the sequel. \n","\"\"\"\n","\n","predict_sentiment(tricky_test) # Ground truth: Negative"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.999: Positive sentiment\n"]}]},{"cell_type":"code","metadata":{"id":"mri8XkffNBRK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637159474062,"user_tz":-540,"elapsed":218,"user":{"displayName":"Ko Kyounghyeon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16783283293138680635"}},"outputId":"7bd3c177-c88c-4285-d9a6-f83be896142e"},"source":["my_review = \"\"\"\n","As it just so happens, one of the main points of \"Cool Cat Saves the Kids\" is\n","in addressing the attitudes of mean naysayers who try to demean others who\n","strive to bring good attitudes and fun vibes into people's lives.\n","\"\"\"\n","predict_sentiment(my_review ) # Ground truth: Positive"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.991: Positive sentiment\n"]}]},{"cell_type":"code","metadata":{"id":"rPb1pECjzq8V"},"source":["# Q18. Which model was able to perform the best on all the test texts, especially on tricky_test, and your own review? \n","# Comment on the overall performance of RNN-based models.\n","# My model was failed to classify the tricky_test review.."],"execution_count":null,"outputs":[]}]}